{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916e47cf",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf03047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wrangle\n",
    "import explore\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0225edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire the data\n",
    "zillow = wrangle.wrangle_zillow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67beaca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 67783 entries, 0 to 77380\n",
      "Data columns (total 14 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   bathroom_count             67783 non-null  float64\n",
      " 1   quality_type               67783 non-null  float64\n",
      " 2   home_square_feet           67783 non-null  float64\n",
      " 3   latitude                   67783 non-null  float64\n",
      " 4   longitude                  67783 non-null  float64\n",
      " 5   room_count                 67783 non-null  float64\n",
      " 6   logerror                   67783 non-null  float64\n",
      " 7   county                     67783 non-null  object \n",
      " 8   age                        67783 non-null  float64\n",
      " 9   acres                      67783 non-null  float64\n",
      " 10  tax_rate                   67783 non-null  float64\n",
      " 11  structure_dollar_per_sqft  67783 non-null  float64\n",
      " 12  land_dollar_per_sqft       67783 non-null  float64\n",
      " 13  bath_bed_ratio             67783 non-null  float64\n",
      "dtypes: float64(13), object(1)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "zillow.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b75de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37958, 14), (16268, 14), (13557, 14))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate, test = wrangle.train_validate_test_split(zillow)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f457819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now make the clusters\n",
    "#Create the list of dictionaries for the cluster groups\n",
    "clusters = [\n",
    "    {\n",
    "        'name':'age_location_cluster',\n",
    "        'k': 6,\n",
    "        'features': ['age', 'latitude', 'longitude']\n",
    "    },\n",
    "    {\n",
    "        'name':'size_cluster',\n",
    "        'k': 5,\n",
    "        'features': ['home_square_feet', 'bath_bed_ratio', 'acres']\n",
    "    },\n",
    "    {\n",
    "        'name':'value_cluster',\n",
    "        'k': 5,\n",
    "        'features': ['structure_dollar_per_sqft', 'land_dollar_per_sqft']\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e78ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = explore.get_clusters(train, validate, test, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615f963a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37958, 17), (16268, 17), (13557, 17))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d67e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, set the int categoricals to dtype 'object'\n",
    "train[['age_location_cluster', 'size_cluster', 'value_cluster']] = train[['age_location_cluster', 'size_cluster', 'value_cluster']].astype('object')\n",
    "validate[['age_location_cluster', 'size_cluster', 'value_cluster']] = validate[['age_location_cluster', 'size_cluster', 'value_cluster']].astype('object')\n",
    "test[['age_location_cluster', 'size_cluster', 'value_cluster']] = test[['age_location_cluster', 'size_cluster', 'value_cluster']].astype('object')\n",
    "\n",
    "#Get cols to create dummies for\n",
    "cat_cols = ['county', 'age_location_cluster', 'size_cluster', 'value_cluster']\n",
    "\n",
    "df_dummies = pd.get_dummies(train[cat_cols], dummy_na=False, drop_first=True)\n",
    "train = pd.concat([train, df_dummies], axis = 1).drop(columns = cat_cols)\n",
    "\n",
    "df_dummies = pd.get_dummies(validate[cat_cols], dummy_na=False, drop_first=True)\n",
    "validate = pd.concat([validate, df_dummies], axis = 1).drop(columns = cat_cols)\n",
    "\n",
    "df_dummies = pd.get_dummies(test[cat_cols], dummy_na=False, drop_first=True)\n",
    "test = pd.concat([test, df_dummies], axis = 1).drop(columns = cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc3697f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37958, 28), (16268, 28), (13557, 28))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca0d508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16268 entries, 43229 to 1245\n",
      "Data columns (total 28 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   bathroom_count             16268 non-null  float64\n",
      " 1   quality_type               16268 non-null  float64\n",
      " 2   home_square_feet           16268 non-null  float64\n",
      " 3   latitude                   16268 non-null  float64\n",
      " 4   longitude                  16268 non-null  float64\n",
      " 5   room_count                 16268 non-null  float64\n",
      " 6   logerror                   16268 non-null  float64\n",
      " 7   age                        16268 non-null  float64\n",
      " 8   acres                      16268 non-null  float64\n",
      " 9   tax_rate                   16268 non-null  float64\n",
      " 10  structure_dollar_per_sqft  16268 non-null  float64\n",
      " 11  land_dollar_per_sqft       16268 non-null  float64\n",
      " 12  bath_bed_ratio             16268 non-null  float64\n",
      " 13  county_Orange              16268 non-null  uint8  \n",
      " 14  county_Ventura             16268 non-null  uint8  \n",
      " 15  age_location_cluster_1     16268 non-null  uint8  \n",
      " 16  age_location_cluster_2     16268 non-null  uint8  \n",
      " 17  age_location_cluster_3     16268 non-null  uint8  \n",
      " 18  age_location_cluster_4     16268 non-null  uint8  \n",
      " 19  age_location_cluster_5     16268 non-null  uint8  \n",
      " 20  size_cluster_1             16268 non-null  uint8  \n",
      " 21  size_cluster_2             16268 non-null  uint8  \n",
      " 22  size_cluster_3             16268 non-null  uint8  \n",
      " 23  size_cluster_4             16268 non-null  uint8  \n",
      " 24  value_cluster_1            16268 non-null  uint8  \n",
      " 25  value_cluster_2            16268 non-null  uint8  \n",
      " 26  value_cluster_3            16268 non-null  uint8  \n",
      " 27  value_cluster_4            16268 non-null  uint8  \n",
      "dtypes: float64(13), uint8(15)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "validate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7747f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into X and y groups\n",
    "X_train, y_train = train.drop('logerror', axis = 1), train.logerror\n",
    "X_validate, y_validate = validate.drop('logerror', axis = 1), validate.logerror\n",
    "X_test, y_test = test.drop('logerror', axis = 1), test.logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05c4a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now scale the X groups using the MinMax Scaler\n",
    "def scale_data(X_train, X_validate, X_test):\n",
    "    #Create the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    #Fit the scaler on X_train\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    #Transform the data\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_validate_scaled = scaler.transform(X_validate)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_validate_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e676b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_validate_scaled, X_test_scaled = scale_data(X_train, X_validate, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "341b2355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the metric dataframe\n",
    "metric_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d403bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metric_df(y, y_pred, model_name, metric_df):\n",
    "    if metric_df.size ==0:\n",
    "        metric_df = pd.DataFrame(data=[\n",
    "            {\n",
    "                'model': model_name, \n",
    "                'RMSE_validate': mean_squared_error(\n",
    "                    y,\n",
    "                    y_pred) ** .5,\n",
    "                'r^2_validate': explained_variance_score(\n",
    "                    y,\n",
    "                    y_pred)\n",
    "            }])\n",
    "        return metric_df\n",
    "    else:\n",
    "        return metric_df.append(\n",
    "            {\n",
    "                'model': model_name, \n",
    "                'RMSE_validate': mean_squared_error(\n",
    "                    y,\n",
    "                    y_pred) ** .5,\n",
    "                'r^2_validate': explained_variance_score(\n",
    "                    y,\n",
    "                    y_pred)\n",
    "            }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63383669",
   "metadata": {},
   "source": [
    "__Create the Baseline__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b491f892",
   "metadata": {},
   "source": [
    "I will create the baseline using the mean of logerror."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ab43f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the baseline and print the RMSE\n",
    "def get_baseline(y_train, y_validate, y_test, metric_df):\n",
    "    #Change y_train and y_validate to be data frames so we can store the baseline values in them\n",
    "    y_train = pd.DataFrame(y_train)\n",
    "    y_validate = pd.DataFrame(y_validate)\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "\n",
    "    #Calculate baseline based on mean\n",
    "    baseline_mean_pred = y_train.logerror.mean()\n",
    "    y_train['baseline_mean_pred'] = baseline_mean_pred\n",
    "    y_validate['baseline_mean_pred'] = baseline_mean_pred\n",
    "    y_test['baseline_mean_pred'] = baseline_mean_pred\n",
    "\n",
    "    #Calculate RMSE based on mean\n",
    "    train_RMSE = mean_squared_error(y_train.logerror, y_train['baseline_mean_pred']) ** .5\n",
    "    validate_RMSE = mean_squared_error(y_validate.logerror, y_validate['baseline_mean_pred']) ** .5\n",
    "\n",
    "    #Print RMSE\n",
    "    print(\"RMSE using Mean\\nTrain/In-Sample: \", round(train_RMSE, 4), \n",
    "        \"\\nValidate/Out-of-Sample: \", round(validate_RMSE, 4),\n",
    "        \"\\n\")\n",
    "\n",
    "    metric_df = make_metric_df(y_validate.logerror, y_validate['baseline_mean_pred'], 'validate_baseline_mean', metric_df)\n",
    "\n",
    "    return y_train, y_validate, y_test, metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b32cd3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using Mean\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train, y_validate, y_test, metric_df = get_baseline(y_train, y_validate, y_test, metric_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d49f71",
   "metadata": {},
   "source": [
    "__Create OLS Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a632d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ols_model(X_train_scaled, X_validate_scaled, y_train, y_validate, metric_df):\n",
    "    #Create the model\n",
    "    lm = LinearRegression(normalize = True)\n",
    "\n",
    "    #Fit the model on scaled data\n",
    "    lm.fit(X_train_scaled, y_train.logerror)\n",
    "\n",
    "    #Make predictions\n",
    "    y_train['lm_preds'] = lm.predict(X_train_scaled)\n",
    "    y_validate['lm_preds'] = lm.predict(X_validate_scaled)\n",
    "\n",
    "    #Calculate the RMSE\n",
    "    train_RMSE = mean_squared_error(y_train.logerror, y_train['lm_preds']) ** .5\n",
    "    validate_RMSE = mean_squared_error(y_validate.logerror, y_validate['lm_preds']) ** .5\n",
    "\n",
    "    print(\"RMSE using OLS\\nTrain/In-Sample: \", round(train_RMSE, 4), \n",
    "        \"\\nValidate/Out-of-Sample: \", round(validate_RMSE, 4))\n",
    "\n",
    "    metric_df = make_metric_df(y_validate.logerror, y_validate['lm_preds'], 'validate_ols', metric_df)\n",
    "\n",
    "    return lm, metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aba796c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using OLS\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1536\n"
     ]
    }
   ],
   "source": [
    "lm, metric_df = get_ols_model(X_train_scaled, X_validate_scaled, y_train, y_validate, metric_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5cb530",
   "metadata": {},
   "source": [
    "__Create LassoLars Models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1639dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lars_models(X_train_scaled, X_validate_scaled, y_train, y_validate, metric_df):\n",
    "    #Create a list to hold all the different models\n",
    "    lars_models = []\n",
    "\n",
    "    #Loop through different alpha values. Start with 1.\n",
    "    for i in range(1, 21):\n",
    "        #Create the model\n",
    "        lars = LassoLars(alpha = i)\n",
    "        \n",
    "        #Fit the model\n",
    "        lars.fit(X_train_scaled, y_train.logerror)\n",
    "        \n",
    "        #Make predictions\n",
    "        y_train[f'lars_alpha_{i}'] = lars.predict(X_train_scaled)\n",
    "        y_validate[f'lars_alpha_{i}'] = lars.predict(X_validate_scaled)\n",
    "        \n",
    "        #Calculate RMSE\n",
    "        train_RMSE = mean_squared_error(y_train.logerror, y_train[f'lars_alpha_{i}']) ** .5\n",
    "        validate_RMSE = mean_squared_error(y_validate.logerror, y_validate[f'lars_alpha_{i}']) ** .5\n",
    "\n",
    "        #Add model to list of lars models\n",
    "        lars_models.append({f'lars_alpha_{i}': lars})\n",
    "        \n",
    "        print(f'\\nRMSE using LassoLars, alpha = {i}')\n",
    "        print(\"Train/In-Sample: \", round(train_RMSE, 4), \n",
    "        \"\\nValidate/Out-of-Sample: \", round(validate_RMSE, 4))\n",
    "\n",
    "        metric_df = make_metric_df(y_validate.logerror, y_validate[f'lars_alpha_{i}'], f'validate_lars_alpha_{i}', metric_df)\n",
    "\n",
    "    return lars_models, metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8735dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE using LassoLars, alpha = 1\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 2\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 3\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 4\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 5\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 6\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 7\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 8\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 9\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 10\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 11\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 12\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 13\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 14\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 15\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 16\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 17\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 18\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 19\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE using LassoLars, alpha = 20\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n"
     ]
    }
   ],
   "source": [
    "lars_models, metric_df = get_lars_models(X_train_scaled, X_validate_scaled, y_train, y_validate, metric_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612dfac9",
   "metadata": {},
   "source": [
    "__Create GLM, Tweedie Regressor Models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a439335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glm_model(X_train_scaled, X_validate_scaled, y_train, y_validate, metric_df):\n",
    "    #Create a list to hold all the models\n",
    "    glm_models = []\n",
    "\n",
    "    #Use a loop to try each power and several values for alpha\n",
    "    for i in range(0, 3):\n",
    "        if i == 1 or i == 2:\n",
    "            continue\n",
    "        else:\n",
    "            #The following loop determines the alpha values\n",
    "            for j in range(1, 11):\n",
    "                #Create the model\n",
    "                glm = TweedieRegressor(power = i, alpha = j)\n",
    "\n",
    "                #Fit the model\n",
    "                glm.fit(X_train_scaled, y_train.logerror)\n",
    "\n",
    "                #Make predictions\n",
    "                y_train[f'glm_power_{i}_alpha_{j}_preds'] = glm.predict(X_train_scaled)\n",
    "                y_validate[f'glm_power_{i}_alpha_{j}_preds'] = glm.predict(X_validate_scaled)\n",
    "\n",
    "                #Calculate RMSE\n",
    "                train_RMSE = mean_squared_error(y_train.logerror, y_train[f'glm_power_{i}_alpha_{j}_preds']) ** .5\n",
    "                validate_RMSE = mean_squared_error(y_validate.logerror, y_validate[f'glm_power_{i}_alpha_{j}_preds']) ** .5\n",
    "\n",
    "                #Add model to the list\n",
    "                glm_models.append({f'glm_{i}_{j}':glm})\n",
    "\n",
    "                print(f'\\nRMSE for Power = {i}, Alpha = {j}\\n')\n",
    "                print(\"Train/In-Sample: \", round(train_RMSE, 4), \n",
    "                    \"\\nValidate/Out-of-Sample: \", round(validate_RMSE, 4))\n",
    "\n",
    "                metric_df = make_metric_df(y_validate.logerror, y_validate[f'glm_power_{i}_alpha_{j}_preds'], f'validate_glm_power_{i}_alpha_{j}', metric_df)\n",
    "\n",
    "    return glm_models, metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c001ab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE for Power = 0, Alpha = 1\n",
      "\n",
      "Train/In-Sample:  0.1684 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Power = 0, Alpha = 2\n",
      "\n",
      "Train/In-Sample:  0.1684 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Power = 0, Alpha = 3\n",
      "\n",
      "Train/In-Sample:  0.1684 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE for Power = 0, Alpha = 4\n",
      "\n",
      "Train/In-Sample:  0.1684 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE for Power = 0, Alpha = 5\n",
      "\n",
      "Train/In-Sample:  0.1684 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE for Power = 0, Alpha = 6\n",
      "\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE for Power = 0, Alpha = 7\n",
      "\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE for Power = 0, Alpha = 8\n",
      "\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE for Power = 0, Alpha = 9\n",
      "\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n",
      "\n",
      "RMSE for Power = 0, Alpha = 10\n",
      "\n",
      "Train/In-Sample:  0.1685 \n",
      "Validate/Out-of-Sample:  0.1538\n"
     ]
    }
   ],
   "source": [
    "glm, metric_df = get_glm_model(X_train_scaled, X_validate_scaled, y_train, y_validate, metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aad3b37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE_validate</th>\n",
       "      <th>r^2_validate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validate_baseline_mean</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validate_ols</td>\n",
       "      <td>0.153585</td>\n",
       "      <td>0.002691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>validate_lars_alpha_1</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>validate_lars_alpha_2</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>validate_lars_alpha_3</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>validate_lars_alpha_4</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>validate_lars_alpha_5</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>validate_lars_alpha_6</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>validate_lars_alpha_7</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>validate_lars_alpha_8</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>validate_lars_alpha_9</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>validate_lars_alpha_10</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>validate_lars_alpha_11</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>validate_lars_alpha_12</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>validate_lars_alpha_13</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>validate_lars_alpha_14</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>validate_lars_alpha_15</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>validate_lars_alpha_16</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>validate_lars_alpha_17</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>validate_lars_alpha_18</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>validate_lars_alpha_19</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>validate_lars_alpha_20</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>validate_glm_power_0_alpha_1</td>\n",
       "      <td>0.153725</td>\n",
       "      <td>0.000867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>validate_glm_power_0_alpha_2</td>\n",
       "      <td>0.153750</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>validate_glm_power_0_alpha_3</td>\n",
       "      <td>0.153762</td>\n",
       "      <td>0.000376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>validate_glm_power_0_alpha_4</td>\n",
       "      <td>0.153768</td>\n",
       "      <td>0.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>validate_glm_power_0_alpha_5</td>\n",
       "      <td>0.153770</td>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>validate_glm_power_0_alpha_6</td>\n",
       "      <td>0.153774</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>validate_glm_power_0_alpha_7</td>\n",
       "      <td>0.153775</td>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>validate_glm_power_0_alpha_8</td>\n",
       "      <td>0.153780</td>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>validate_glm_power_0_alpha_9</td>\n",
       "      <td>0.153781</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>validate_glm_power_0_alpha_10</td>\n",
       "      <td>0.153783</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  RMSE_validate  r^2_validate\n",
       "0          validate_baseline_mean       0.153790      0.000000\n",
       "1                    validate_ols       0.153585      0.002691\n",
       "2           validate_lars_alpha_1       0.153790      0.000000\n",
       "3           validate_lars_alpha_2       0.153790      0.000000\n",
       "4           validate_lars_alpha_3       0.153790      0.000000\n",
       "5           validate_lars_alpha_4       0.153790      0.000000\n",
       "6           validate_lars_alpha_5       0.153790      0.000000\n",
       "7           validate_lars_alpha_6       0.153790      0.000000\n",
       "8           validate_lars_alpha_7       0.153790      0.000000\n",
       "9           validate_lars_alpha_8       0.153790      0.000000\n",
       "10          validate_lars_alpha_9       0.153790      0.000000\n",
       "11         validate_lars_alpha_10       0.153790      0.000000\n",
       "12         validate_lars_alpha_11       0.153790      0.000000\n",
       "13         validate_lars_alpha_12       0.153790      0.000000\n",
       "14         validate_lars_alpha_13       0.153790      0.000000\n",
       "15         validate_lars_alpha_14       0.153790      0.000000\n",
       "16         validate_lars_alpha_15       0.153790      0.000000\n",
       "17         validate_lars_alpha_16       0.153790      0.000000\n",
       "18         validate_lars_alpha_17       0.153790      0.000000\n",
       "19         validate_lars_alpha_18       0.153790      0.000000\n",
       "20         validate_lars_alpha_19       0.153790      0.000000\n",
       "21         validate_lars_alpha_20       0.153790      0.000000\n",
       "22   validate_glm_power_0_alpha_1       0.153725      0.000867\n",
       "23   validate_glm_power_0_alpha_2       0.153750      0.000527\n",
       "24   validate_glm_power_0_alpha_3       0.153762      0.000376\n",
       "25   validate_glm_power_0_alpha_4       0.153768      0.000293\n",
       "26   validate_glm_power_0_alpha_5       0.153770      0.000243\n",
       "27   validate_glm_power_0_alpha_6       0.153774      0.000203\n",
       "28   validate_glm_power_0_alpha_7       0.153775      0.000177\n",
       "29   validate_glm_power_0_alpha_8       0.153780      0.000155\n",
       "30   validate_glm_power_0_alpha_9       0.153781      0.000139\n",
       "31  validate_glm_power_0_alpha_10       0.153783      0.000126"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd17ef0",
   "metadata": {},
   "source": [
    "__Create RandomForestRegressor Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70aee2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE for Max Depth = 2, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 2, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 2, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 2, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 2, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 2, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 3, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1676 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 3, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1676 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 3, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1676 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 3, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1676 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 3, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1677 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 3, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1677 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 4, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1672 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 4, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1672 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 4, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1672 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 4, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1672 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 4, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1672 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 4, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1673 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 5, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1666 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 5, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1666 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 5, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1667 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 5, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1667 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 5, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1667 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 5, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1668 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 6, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.166 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 6, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.166 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 6, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1661 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 6, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1661 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 6, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1661 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 6, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1662 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 7, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1653 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 7, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1654 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 7, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1654 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 7, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1654 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 7, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1655 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 7, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1656 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 8, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1645 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 8, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1646 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 8, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1646 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 8, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1647 \n",
      "Validate/Out-of-Sample:  0.1535\n",
      "\n",
      "RMSE for Max Depth = 8, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1648 \n",
      "Validate/Out-of-Sample:  0.1535\n",
      "\n",
      "RMSE for Max Depth = 8, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1649 \n",
      "Validate/Out-of-Sample:  0.1535\n",
      "\n",
      "RMSE for Max Depth = 9, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1636 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 9, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1637 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 9, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1638 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 9, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1639 \n",
      "Validate/Out-of-Sample:  0.1535\n",
      "\n",
      "RMSE for Max Depth = 9, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.164 \n",
      "Validate/Out-of-Sample:  0.1535\n",
      "\n",
      "RMSE for Max Depth = 9, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1641 \n",
      "Validate/Out-of-Sample:  0.1535\n",
      "\n",
      "RMSE for Max Depth = 10, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1626 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 10, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1628 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 10, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1629 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 10, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.163 \n",
      "Validate/Out-of-Sample:  0.1535\n",
      "\n",
      "RMSE for Max Depth = 10, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1632 \n",
      "Validate/Out-of-Sample:  0.1535\n",
      "\n",
      "RMSE for Max Depth = 10, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1633 \n",
      "Validate/Out-of-Sample:  0.1535\n"
     ]
    }
   ],
   "source": [
    "#Starting from 2 in order to avoid warnings\n",
    "rfr_models = []\n",
    "\n",
    "for num in range(2, 11):\n",
    "    #Now create a new loop that runs through different min_samples_leaf values\n",
    "    for val in range(10, 16):\n",
    "        #Instantiate new model\n",
    "        model = RandomForestRegressor(random_state = 123, max_depth = num, min_samples_leaf = val)\n",
    "\n",
    "        #Fit the model\n",
    "        model.fit(X_train_scaled, y_train.logerror)\n",
    "\n",
    "        #Make predictions\n",
    "        y_train[f'rfr_depth_{num}_samples_{val}_preds'] = model.predict(X_train_scaled)\n",
    "        y_validate[f'rfr_depth_{num}_samples_{val}_preds'] = model.predict(X_validate_scaled)\n",
    "        \n",
    "        #Calculate RMSE\n",
    "        train_RMSE = mean_squared_error(y_train.logerror, y_train[f'rfr_depth_{num}_samples_{val}_preds']) ** .5\n",
    "        validate_RMSE = mean_squared_error(y_validate.logerror, y_validate[f'rfr_depth_{num}_samples_{val}_preds']) ** .5\n",
    "\n",
    "        #Add model to the list\n",
    "        rfr_models.append({f'rfr_depth_{num}_samples_{val}': model})\n",
    "\n",
    "        print(f'\\nRMSE for Max Depth = {num}, Min Samples = {val}\\n')\n",
    "        print(\"Train/In-Sample: \", round(train_RMSE, 4), \n",
    "            \"\\nValidate/Out-of-Sample: \", round(validate_RMSE, 4))\n",
    "    \n",
    "        #Add results to metric dataframe\n",
    "        metric_df = make_metric_df(y_validate.logerror, y_validate[f'rfr_depth_{num}_samples_{val}_preds'], f'validate_rfr_depth_{num}_samples_{val}', metric_df)\n",
    "       \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25147c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85    0.003946\n",
       "79    0.003730\n",
       "77    0.003595\n",
       "83    0.003585\n",
       "84    0.003581\n",
       "Name: r^2_validate, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df['r^2_validate'].sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70be0314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE_validate</th>\n",
       "      <th>r^2_validate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validate_baseline_mean</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validate_ols</td>\n",
       "      <td>0.153585</td>\n",
       "      <td>0.002691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>validate_lars_alpha_1</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>validate_lars_alpha_2</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>validate_lars_alpha_3</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>validate_rfr_depth_10_samples_11</td>\n",
       "      <td>0.153579</td>\n",
       "      <td>0.002840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>validate_rfr_depth_10_samples_12</td>\n",
       "      <td>0.153559</td>\n",
       "      <td>0.003093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>validate_rfr_depth_10_samples_13</td>\n",
       "      <td>0.153521</td>\n",
       "      <td>0.003585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>validate_rfr_depth_10_samples_14</td>\n",
       "      <td>0.153521</td>\n",
       "      <td>0.003581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>validate_rfr_depth_10_samples_15</td>\n",
       "      <td>0.153493</td>\n",
       "      <td>0.003946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model  RMSE_validate  r^2_validate\n",
       "0             validate_baseline_mean       0.153790      0.000000\n",
       "1                       validate_ols       0.153585      0.002691\n",
       "2              validate_lars_alpha_1       0.153790      0.000000\n",
       "3              validate_lars_alpha_2       0.153790      0.000000\n",
       "4              validate_lars_alpha_3       0.153790      0.000000\n",
       "..                               ...            ...           ...\n",
       "81  validate_rfr_depth_10_samples_11       0.153579      0.002840\n",
       "82  validate_rfr_depth_10_samples_12       0.153559      0.003093\n",
       "83  validate_rfr_depth_10_samples_13       0.153521      0.003585\n",
       "84  validate_rfr_depth_10_samples_14       0.153521      0.003581\n",
       "85  validate_rfr_depth_10_samples_15       0.153493      0.003946\n",
       "\n",
       "[86 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b6864bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rfr_models[53]['rfr_depth_10_samples_15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8eaf68a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.08845731e-02, 1.03652453e-02, 1.43576261e-01, 1.32048357e-01,\n",
       "       1.14306713e-01, 1.15514286e-02, 9.09824386e-02, 9.97601509e-02,\n",
       "       9.01183518e-02, 1.51919655e-01, 9.25490393e-02, 2.38642895e-02,\n",
       "       8.97616369e-04, 0.00000000e+00, 1.21860684e-03, 0.00000000e+00,\n",
       "       1.59095448e-03, 5.07780862e-03, 4.81827705e-05, 2.28675875e-03,\n",
       "       1.07200470e-03, 7.13311545e-04, 3.41749537e-04, 2.42128918e-03,\n",
       "       0.00000000e+00, 2.70805671e-04, 2.13440844e-03])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5a7f273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bathroom_count', 'quality_type', 'home_square_feet', 'latitude',\n",
       "       'longitude', 'room_count', 'age', 'acres', 'tax_rate',\n",
       "       'structure_dollar_per_sqft', 'land_dollar_per_sqft', 'bath_bed_ratio',\n",
       "       'county_Orange', 'county_Ventura', 'age_location_cluster_1',\n",
       "       'age_location_cluster_2', 'age_location_cluster_3',\n",
       "       'age_location_cluster_4', 'age_location_cluster_5', 'size_cluster_1',\n",
       "       'size_cluster_2', 'size_cluster_3', 'size_cluster_4', 'value_cluster_1',\n",
       "       'value_cluster_2', 'value_cluster_3', 'value_cluster_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95f5cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = pd.DataFrame(X_train.columns, best_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ca65eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.020885</th>\n",
       "      <td>bathroom_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010365</th>\n",
       "      <td>quality_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.143576</th>\n",
       "      <td>home_square_feet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.132048</th>\n",
       "      <td>latitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.114307</th>\n",
       "      <td>longitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.011551</th>\n",
       "      <td>room_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.090982</th>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.099760</th>\n",
       "      <td>acres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.090118</th>\n",
       "      <td>tax_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.151920</th>\n",
       "      <td>structure_dollar_per_sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.092549</th>\n",
       "      <td>land_dollar_per_sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.023864</th>\n",
       "      <td>bath_bed_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000898</th>\n",
       "      <td>county_Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>county_Ventura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001219</th>\n",
       "      <td>age_location_cluster_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>age_location_cluster_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001591</th>\n",
       "      <td>age_location_cluster_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005078</th>\n",
       "      <td>age_location_cluster_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000048</th>\n",
       "      <td>age_location_cluster_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002287</th>\n",
       "      <td>size_cluster_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001072</th>\n",
       "      <td>size_cluster_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000713</th>\n",
       "      <td>size_cluster_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000342</th>\n",
       "      <td>size_cluster_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002421</th>\n",
       "      <td>value_cluster_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>value_cluster_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000271</th>\n",
       "      <td>value_cluster_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002134</th>\n",
       "      <td>value_cluster_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0\n",
       "0.020885             bathroom_count\n",
       "0.010365               quality_type\n",
       "0.143576           home_square_feet\n",
       "0.132048                   latitude\n",
       "0.114307                  longitude\n",
       "0.011551                 room_count\n",
       "0.090982                        age\n",
       "0.099760                      acres\n",
       "0.090118                   tax_rate\n",
       "0.151920  structure_dollar_per_sqft\n",
       "0.092549       land_dollar_per_sqft\n",
       "0.023864             bath_bed_ratio\n",
       "0.000898              county_Orange\n",
       "0.000000             county_Ventura\n",
       "0.001219     age_location_cluster_1\n",
       "0.000000     age_location_cluster_2\n",
       "0.001591     age_location_cluster_3\n",
       "0.005078     age_location_cluster_4\n",
       "0.000048     age_location_cluster_5\n",
       "0.002287             size_cluster_1\n",
       "0.001072             size_cluster_2\n",
       "0.000713             size_cluster_3\n",
       "0.000342             size_cluster_4\n",
       "0.002421            value_cluster_1\n",
       "0.000000            value_cluster_2\n",
       "0.000271            value_cluster_3\n",
       "0.002134            value_cluster_4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8c449b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bathroom_count', 'quality_type', 'home_square_feet', 'latitude',\n",
       "       'longitude', 'room_count', 'logerror', 'age', 'acres', 'tax_rate',\n",
       "       'structure_dollar_per_sqft', 'land_dollar_per_sqft', 'bath_bed_ratio',\n",
       "       'county_Orange', 'county_Ventura', 'age_location_cluster_1',\n",
       "       'age_location_cluster_2', 'age_location_cluster_3',\n",
       "       'age_location_cluster_4', 'age_location_cluster_5', 'size_cluster_1',\n",
       "       'size_cluster_2', 'size_cluster_3', 'size_cluster_4', 'value_cluster_1',\n",
       "       'value_cluster_2', 'value_cluster_3', 'value_cluster_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf428917",
   "metadata": {},
   "source": [
    "### Are my clusters more of a hindrance than anything else? Try running the rfr models without the cluster groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "885bc6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['bathroom_count', 'quality_type', 'home_square_feet', 'latitude',\n",
    "       'longitude', 'room_count', 'age', 'acres', 'tax_rate',\n",
    "       'structure_dollar_per_sqft', 'land_dollar_per_sqft', 'bath_bed_ratio',\n",
    "       'county_Orange', 'county_Ventura']]\n",
    "\n",
    "y_train = train.logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "569fca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate[['bathroom_count', 'quality_type', 'home_square_feet', 'latitude',\n",
    "       'longitude', 'room_count', 'age', 'acres', 'tax_rate',\n",
    "       'structure_dollar_per_sqft', 'land_dollar_per_sqft', 'bath_bed_ratio',\n",
    "       'county_Orange', 'county_Ventura']]\n",
    "\n",
    "y_validate = validate.logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "615ac7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now scale the data sets\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_validate_scaled = scaler.transform(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f0fb712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the y sets into dataframes\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_validate = pd.DataFrame(y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdbfc1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE for Max Depth = 2, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 2, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 2, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 2, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 2, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 2, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.168 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 3, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1677 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 3, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1676 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 3, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1677 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 3, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1677 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 3, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1677 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 3, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1677 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 4, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1672 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 4, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1672 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 4, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1672 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 4, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1672 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 4, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1672 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 4, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1673 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 5, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1667 \n",
      "Validate/Out-of-Sample:  0.1537\n",
      "\n",
      "RMSE for Max Depth = 5, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1667 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 5, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1667 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 5, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1667 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 5, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1667 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 5, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1668 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 6, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.166 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 6, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1661 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 6, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1661 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 6, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1661 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 6, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1662 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 6, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1662 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 7, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1653 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 7, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1654 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 7, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1654 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 7, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1655 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 7, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1655 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 7, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1656 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 8, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1645 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 8, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1646 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 8, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1647 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 8, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1648 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 8, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1648 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 8, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1649 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 9, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1636 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 9, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1638 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 9, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.1639 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 9, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1639 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 9, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.164 \n",
      "Validate/Out-of-Sample:  0.1535\n",
      "\n",
      "RMSE for Max Depth = 9, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1641 \n",
      "Validate/Out-of-Sample:  0.1535\n",
      "\n",
      "RMSE for Max Depth = 10, Min Samples = 10\n",
      "\n",
      "Train/In-Sample:  0.1626 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 10, Min Samples = 11\n",
      "\n",
      "Train/In-Sample:  0.1628 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 10, Min Samples = 12\n",
      "\n",
      "Train/In-Sample:  0.163 \n",
      "Validate/Out-of-Sample:  0.1536\n",
      "\n",
      "RMSE for Max Depth = 10, Min Samples = 13\n",
      "\n",
      "Train/In-Sample:  0.1631 \n",
      "Validate/Out-of-Sample:  0.1535\n",
      "\n",
      "RMSE for Max Depth = 10, Min Samples = 14\n",
      "\n",
      "Train/In-Sample:  0.1632 \n",
      "Validate/Out-of-Sample:  0.1535\n",
      "\n",
      "RMSE for Max Depth = 10, Min Samples = 15\n",
      "\n",
      "Train/In-Sample:  0.1633 \n",
      "Validate/Out-of-Sample:  0.1535\n"
     ]
    }
   ],
   "source": [
    "for num in range(2, 11):\n",
    "    #Now create a new loop that runs through different min_samples_leaf values\n",
    "    for val in range(10, 16):\n",
    "        #Instantiate new model\n",
    "        model = RandomForestRegressor(random_state = 123, max_depth = num, min_samples_leaf = val)\n",
    "\n",
    "        #Fit the model\n",
    "        model.fit(X_train_scaled, y_train.logerror)\n",
    "\n",
    "        #Make predictions\n",
    "        y_train[f'rfr_depth_{num}_samples_{val}_preds'] = model.predict(X_train_scaled)\n",
    "        y_validate[f'rfr_depth_{num}_samples_{val}_preds'] = model.predict(X_validate_scaled)\n",
    "        \n",
    "        #Calculate RMSE\n",
    "        train_RMSE = mean_squared_error(y_train.logerror, y_train[f'rfr_depth_{num}_samples_{val}_preds']) ** .5\n",
    "        validate_RMSE = mean_squared_error(y_validate.logerror, y_validate[f'rfr_depth_{num}_samples_{val}_preds']) ** .5\n",
    "\n",
    "        #Add model to the list\n",
    "        rfr_models.append({f'rfr_depth_{num}_samples_{val}_no_clusters': model})\n",
    "\n",
    "        print(f'\\nRMSE for Max Depth = {num}, Min Samples = {val}\\n')\n",
    "        print(\"Train/In-Sample: \", round(train_RMSE, 4), \n",
    "            \"\\nValidate/Out-of-Sample: \", round(validate_RMSE, 4))\n",
    "    \n",
    "        #Add results to metric dataframe\n",
    "        metric_df = make_metric_df(y_validate.logerror, y_validate[f'rfr_depth_{num}_samples_{val}_preds'], f'validate_rfr_depth_{num}_samples_{val}_no_clusters', metric_df)\n",
    "       \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e78242f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85     0.003946\n",
       "139    0.003748\n",
       "79     0.003730\n",
       "77     0.003595\n",
       "83     0.003585\n",
       "Name: r^2_validate, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df['r^2_validate'].sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab16f2",
   "metadata": {},
   "source": [
    "### It seems that while my clusters had small feature importance values, they are still useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32298a19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
